import os
import urllib.request
import urllib.parse
import urllib.error
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Optional, Tuple
import threading
import time

def ensure_models_directory(base_path: Optional[str] = None) -> str:
    """
    ç¡®ä¿modelsç›®å½•å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
    
    Args:
        base_path: åŸºç¡€è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨__file__çš„çˆ¶ç›®å½•
        
    Returns:
        str: modelsç›®å½•çš„ç»å¯¹è·¯å¾„
        
    Raises:
        OSError: åˆ›å»ºç›®å½•å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
    """
    if base_path is None:
        here = os.path.dirname(__file__)
    else:
        here = base_path
        
    models_dir = os.path.join(here, "..", "..", "models")
    models_dir = os.path.abspath(models_dir)
    
    try:
        Path(models_dir).mkdir(parents=True, exist_ok=True)
        print(f"Models directory ensured: {models_dir}")
        return models_dir
    except OSError as e:
        raise OSError(f"Failed to create models directory {models_dir}: {e}")

def construct_download_url(remote_host: str, model_name: str, file_path: str, 
                          resolve_path: str = "/resolve/main") -> str:
    """
    æ„é€ ä¸‹è½½URL
    
    Args:
        remote_host: è¿œç¨‹ä¸»æœºåœ°å€
        model_name: æ¨¡å‹åç§°
        file_path: æ–‡ä»¶è·¯å¾„
        resolve_path: è§£æè·¯å¾„ï¼Œé»˜è®¤ä¸º/resolve/main
        
    Returns:
        str: å®Œæ•´çš„ä¸‹è½½URL
    """
    # ç¡®ä¿æ‰€æœ‰è·¯å¾„ç»„ä»¶éƒ½æ­£ç¡®æ ¼å¼åŒ–
    if not remote_host.startswith(('http://', 'https://')):
        remote_host = f"https://{remote_host}"
    
    # ç§»é™¤å¤šä½™çš„æ–œæ å¹¶æ„é€ URL
    base_url = remote_host.rstrip('/')
    model_name = model_name.strip('/')
    resolve_path = resolve_path.strip('/')
    file_path = file_path.lstrip('/')
    
    url = f"{base_url}/{model_name}/{resolve_path}/{file_path}"
    return url

def download_single_file(url: str, local_path: str, max_retries: int = 3) -> Tuple[bool, str]:
    """
    ä¸‹è½½å•ä¸ªæ–‡ä»¶
    
    Args:
        url: ä¸‹è½½URL
        local_path: æœ¬åœ°ä¿å­˜è·¯å¾„
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        
    Returns:
        Tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, é”™è¯¯ä¿¡æ¯æˆ–æˆåŠŸä¿¡æ¯)
    """
    thread_id = threading.current_thread().ident
    
    # ç¡®ä¿æœ¬åœ°ç›®å½•å­˜åœ¨
    local_dir = os.path.dirname(local_path)
    try:
        Path(local_dir).mkdir(parents=True, exist_ok=True)
    except OSError as e:
        return False, f"Failed to create directory {local_dir}: {e}"
    
    # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°ä¸‹è½½
    if os.path.exists(local_path):
        print(f"[Thread-{thread_id}] File already exists: {local_path}")
        return True, f"File already exists: {local_path}"
    
    for attempt in range(max_retries):
        try:
            print(f"[Thread-{thread_id}] Downloading (attempt {attempt + 1}/{max_retries}): {url}")
            
            # åˆ›å»ºè¯·æ±‚å¯¹è±¡å¹¶è®¾ç½®User-Agent
            req = urllib.request.Request(url)
            req.add_header('User-Agent', 'Mozilla/5.0 (Python urllib)')
            
            # ä¸‹è½½æ–‡ä»¶
            with urllib.request.urlopen(req, timeout=30) as response:
                # è·å–æ–‡ä»¶å¤§å°
                content_length = response.headers.get('Content-Length')
                if content_length:
                    total_size = int(content_length)
                    print(f"[Thread-{thread_id}] File size: {total_size:,} bytes")
                
                # å†™å…¥æ–‡ä»¶
                with open(local_path, 'wb') as f:
                    downloaded = 0
                    chunk_size = 8192
                    
                    while True:
                        chunk = response.read(chunk_size)
                        if not chunk:
                            break
                        f.write(chunk)
                        downloaded += len(chunk)
                        
                        # æ˜¾ç¤ºè¿›åº¦ï¼ˆæ¯MBæ˜¾ç¤ºä¸€æ¬¡ï¼‰
                        if downloaded % (1024 * 1024) == 0 or downloaded == total_size:
                            if content_length:
                                progress = (downloaded / total_size) * 100
                                print(f"[Thread-{thread_id}] Progress: {progress:.1f}% ({downloaded:,}/{total_size:,} bytes)")
            
            # éªŒè¯ä¸‹è½½çš„æ–‡ä»¶
            if os.path.exists(local_path) and os.path.getsize(local_path) > 0:
                success_msg = f"Successfully downloaded: {local_path}"
                print(f"[Thread-{thread_id}] {success_msg}")
                return True, success_msg
            else:
                raise Exception("Downloaded file is empty or doesn't exist")
                
        except urllib.error.HTTPError as e:
            error_msg = f"HTTP Error {e.code}: {e.reason} for URL: {url}"
            print(f"[Thread-{thread_id}] {error_msg}")
            if e.code == 404:
                return False, f"File not found (404): {url}"
            if attempt == max_retries - 1:
                return False, error_msg
        except urllib.error.URLError as e:
            error_msg = f"URL Error: {e.reason} for URL: {url}"
            print(f"[Thread-{thread_id}] {error_msg}")
            if attempt == max_retries - 1:
                return False, error_msg
        except Exception as e:
            error_msg = f"Unexpected error: {e} for URL: {url}"
            print(f"[Thread-{thread_id}] {error_msg}")
            if attempt == max_retries - 1:
                return False, error_msg
        
        # é‡è¯•å‰ç­‰å¾…
        if attempt < max_retries - 1:
            wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
            print(f"[Thread-{thread_id}] Waiting {wait_time} seconds before retry...")
            time.sleep(wait_time)
    
    return False, f"Failed to download after {max_retries} attempts: {url}"

def download_models_multithreaded(
    remote_host: str = "huggingface.co",
    model_name: str = "Xenova/vit-gpt2-image-captioning", 
    files_to_download: Optional[List[str]] = None,
    resolve_path: str = "/resolve/main",
    max_workers: int = 4,
    base_path: Optional[str] = None
) -> Tuple[List[str], List[str]]:
    """
    å¤šçº¿ç¨‹ä¸‹è½½æ¨¡å‹æ–‡ä»¶
    
    Args:
        remote_host: è¿œç¨‹ä¸»æœºï¼Œé»˜è®¤huggingface.co
        model_name: æ¨¡å‹åç§°ï¼Œé»˜è®¤Xenova/vit-gpt2-image-captioning
        files_to_download: è¦ä¸‹è½½çš„æ–‡ä»¶åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤åˆ—è¡¨
        resolve_path: è§£æè·¯å¾„ï¼Œé»˜è®¤/resolve/main
        max_workers: æœ€å¤§çº¿ç¨‹æ•°ï¼Œé»˜è®¤4
        base_path: åŸºç¡€è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨__file__çš„çˆ¶ç›®å½•
        
    Returns:
        Tuple[List[str], List[str]]: (æˆåŠŸä¸‹è½½çš„æ–‡ä»¶åˆ—è¡¨, å¤±è´¥çš„æ–‡ä»¶åˆ—è¡¨)
        
    Raises:
        ValueError: å‚æ•°æ— æ•ˆæ—¶æŠ›å‡º
        OSError: ç›®å½•æ“ä½œå¤±è´¥æ—¶æŠ›å‡º
    """
    # éªŒè¯å‚æ•°
    if not remote_host or not model_name:
        raise ValueError("remote_host and model_name cannot be empty")
    
    # é»˜è®¤æ–‡ä»¶åˆ—è¡¨
    if files_to_download is None:
        files_to_download = [
            "onnx/encoder_model_quantized.onnx",
            "onnx/decoder_model_merged_quantized.onnx", 
            "config.json",
            "vocab.json"
        ]
    
    if not files_to_download:
        raise ValueError("files_to_download cannot be empty")
    
    print(f"Starting download of {len(files_to_download)} files for model: {model_name}")
    print(f"Remote host: {remote_host}")
    print(f"Max workers: {max_workers}")
    
    # ç¡®ä¿modelsç›®å½•å­˜åœ¨
    models_dir = ensure_models_directory(base_path)
    
    # åˆ›å»ºæœ¬åœ°æ¨¡å‹ç›®å½•
    local_model_dir = os.path.join(models_dir, model_name)
    
    # å‡†å¤‡ä¸‹è½½ä»»åŠ¡
    download_tasks = []
    for file_path in files_to_download:
        url = construct_download_url(remote_host, model_name, file_path, resolve_path)
        local_path = os.path.join(local_model_dir, file_path)
        download_tasks.append((url, local_path, file_path))
    
    successful_downloads = []
    failed_downloads = []
    
    # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œä¸‹è½½
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä¸‹è½½ä»»åŠ¡
        future_to_task = {
            executor.submit(download_single_file, url, local_path): (url, local_path, file_path)
            for url, local_path, file_path in download_tasks
        }
        
        # å¤„ç†å®Œæˆçš„ä»»åŠ¡
        for future in as_completed(future_to_task):
            url, local_path, file_path = future_to_task[future]
            try:
                success, message = future.result()
                if success:
                    successful_downloads.append(file_path)
                    print(f"âœ“ Success: {file_path}")
                else:
                    failed_downloads.append(file_path)
                    print(f"âœ— Failed: {file_path} - {message}")
            except Exception as e:
                failed_downloads.append(file_path)
                print(f"âœ— Exception for {file_path}: {e}")
    
    # æ‰“å°ä¸‹è½½æ‘˜è¦
    print(f"\n=== Download Summary ===")
    print(f"Total files: {len(files_to_download)}")
    print(f"Successful: {len(successful_downloads)}")
    print(f"Failed: {len(failed_downloads)}")
    
    if successful_downloads:
        print(f"\nSuccessful downloads:")
        for file_path in successful_downloads:
            print(f"  âœ“ {file_path}")
    
    if failed_downloads:
        print(f"\nFailed downloads:")
        for file_path in failed_downloads:
            print(f"  âœ— {file_path}")
    
    print(f"\nLocal model directory: {local_model_dir}")
    
    return successful_downloads, failed_downloads

def get_model_file_paths(model_name: str = "Xenova/vit-gpt2-image-captioning", 
                        base_path: Optional[str] = None) -> dict:
    """
    è·å–æ¨¡å‹æ–‡ä»¶çš„æœ¬åœ°è·¯å¾„
    
    Args:
        model_name: æ¨¡å‹åç§°
        base_path: åŸºç¡€è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨__file__çš„çˆ¶ç›®å½•
        
    Returns:
        dict: åŒ…å«å„ä¸ªæ–‡ä»¶è·¯å¾„çš„å­—å…¸
    """
    models_dir = ensure_models_directory(base_path)
    local_model_dir = os.path.join(models_dir, model_name)
    
    return {
        'encoder_path': os.path.join(local_model_dir, "onnx", "encoder_model_quantized.onnx"),
        'decoder_path': os.path.join(local_model_dir, "onnx", "decoder_model_merged_quantized.onnx"),
        'config_path': os.path.join(local_model_dir, "config.json"),
        'vocab_path': os.path.join(local_model_dir, "vocab.json"),
        'model_dir': local_model_dir
    }

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    try:
        # ä¸‹è½½é»˜è®¤æ¨¡å‹
        successful, failed = download_models_multithreaded()
        
        if not failed:
            print("\nğŸ‰ All files downloaded successfully!")
            
            # è·å–æ–‡ä»¶è·¯å¾„
            paths = get_model_file_paths()
            print(f"\nModel file paths:")
            for key, path in paths.items():
                print(f"  {key}: {path}")
        else:
            print(f"\nâš ï¸  Some files failed to download: {failed}")
            
    except Exception as e:
        print(f"Error: {e}")
        